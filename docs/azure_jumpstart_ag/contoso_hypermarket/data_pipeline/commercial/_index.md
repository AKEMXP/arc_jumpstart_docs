---
type: docs
weight: 6
title: Data pipeline
linkTitle: Data pipeline
---

# Commercial data pipeline and reporting across cloud and edge

One of Contoso's biggest objectives is how to use the data coming from their stores and visualize it for business intelligence by leveraging the power of the cloud.

Contoso Hypermarket's commercial data pipeline is designed to streamline and optimize the flow of data related to store orders and inventory management. This robust pipeline integrates data from various stores across the country, ensuring that all relevant information is collected, processed, and analyzed efficiently in the cloud. By leveraging this data pipeline, Contoso Hypermarket can generate valuable commercial insights that are crucial for corporate leadership. These insights help in making informed decisions, improving operational efficiency, and enhancing overall business performance. The data pipeline ensures that the leadership team has a comprehensive view of the store operations, enabling them to identify trends, forecast demand, and manage inventory effectively.

## Architecture

Below is an architecture diagram that shows how the data flows from the store edge locations into the Microsoft Fabric to generate near real-time reports of orders received and processed across various supermarket store locations. This architecture includes a local MQTT broker to relay commercial data to the Event Hub in the Azure Cloud. Azure IoT operations dataflow(s) are implemented to connect edge locations to the cloud to relay commercial data.

![Screenshot showing data pipeline architecture](./img/hypermarket-data-pipeline-architecture.png)

## At the edge location

### SQL Server

The SQL Server at the edge location is responsible for storing and managing the commercial data generated by the Cerebral simulator. It ensures that the data is readily available for processing and analysis. The SQL Server is configured to handle large volumes of data efficiently, providing a reliable storage solution for the edge components. Follow instructions below to view SQL Server pods running on the Edge Kubernetes cluster and connect to SQL Server using Azure Data Studio (ADS) and SQL Server Management Studio (SSMS).

- Log into the _Ag-VM-Client_ VM using the username and password provided in the deployment.
- On the desktop locate _Windows Terminal_ shortcut and double click to open the terminal window.

  ![Screenshot showing Windows Terminal desktop shortcut](./img/hypermarket-locate-terminal-window.png)

- Run _cubectx_ command to verify current Kubernetes context configured. Make sure it shows _seattle_, if not change the context by running _kubectx seattle_ command to switch Kubernetes context.

  ![Screenshot showing current Kubernetes context](./img/hypermarket-terminal-kubectx.png)

- Locate the SQL Server pods running on the Edge Kubernetes cluster by running the following command in the terminal window:

  ```sh
  kubectl get pods -n contoso-hypermarket
  ```

  ![Screenshot showing SQL Server pods](./img/hypermarket-locate-terminal-sqlserver-pods.png)

- As part of the Contoso Hypermarket deployment SQL Server connections to these pods are created in ADS and _SQL Server Endpoints_ shortcut on the desktop to connect using SSMS using the SQL Server endpoints and credentials to connect.

### Connect to SQL Server using ADS

- Open the Azure Data Studio from the desktop shortcut.

  ![Screenshot showing Azure Data Studio](./img/hypermarket-locate-data-studio.png)

- Notice pre-configured SQL Server connections of the edge locations Chicago and Seattle. Click on 1) Connections to view these connections.
  
  ![Screenshot showing Azure Data Studio connections](./img/hypermarket-data-studio-connections.png)

- Click on _Seattle_ SQL Server connection to verify the database and tables created for storing commercial data by expanding _RetailDB_ database and tables.

  ![Screenshot showing Seattle RetailDB database and tables](./img/hypermarket-data-studio-seattle.png)

- Run queries to validate the data being stored and ensure it matches the expected format.

  ![Screenshot showing SQL Server query](./img/hypermarket-data-studio-seattle-query-sales.png)

- View _Sales_ table data from the query results.

  ![Screenshot showing sales table data](./img/hypermarket-data-studio-seattle-view-sales.png)

- Explore other tables and data as needed.

### Connect to SQL Server using SSMS

- Locate _SQL Server Endpoints_ shortcut on the Desktop and open file in notepad to view SQL Server endpoints and credentials and keep it handy to connect using SSMS.

  ![Screenshot showing SQL Server Endpoints shortcut](./img/hypermarket-locate-sql-endpoints.png)

  ![Screenshot showing SQL Server Endpoints details](./img/hypermarket-sql-endpoints-details.png)

- Locate _SQL Server Management Studio_ shortcut on the Desktop and doublec click to connect SQL Server databases in _Seattle_ edge location.

  ![Screenshot showing locating SSMS shortcut on the Desktop](./img/hypermarket-locate-ssms.png)

- Use _Seattle_ edge location SQL Server details and connect to the SQL Server as shown below.

  ![Screenshot showing connect to Seattle SQL Server using SSMS](./img/hypermarket-locate-ssms.png)

- Locate RetailDB database, expand tables, and query _Sales_ table to view sales data.

  ![Screenshot showing Seattle SQL Server RetailDB database details](./img/hypermarket-ssms-database-details.png)

### Cerebral data simulator

The Cerebral data simulator is a critical component of the Contoso Hypermarket solution, designed to generate realistic commercial and operational data. This simulator helps in testing and validating the data pipeline by creating various scenarios that mimic real-world operations. Cerebral simulator is pre-configured to generation simulation data a regular interval and can be monitored using MQTT Explorer installed on _Ag-Client-VM_.

- Use the simulator to test different scenarios and validate the data pipeline's performance.

- Screenshot below shows the Cerebral Simulator pod running on the edge Kubernetes cluster.

  ![Screenshot showing Cerebral data simulator](./img/hypermarket-cerebral-simulator-pod.png)

- Monitor the data being generated using MQTT Explorer as described in the following sections to ensure it is being transmitted to the MQTT broker.

### IoT Operations

The IoT Operations component is responsible for managing the data flow from the edge devices to the cloud. It ensures that the commercial data generated by the Cerebral simulator is transmitted securely and efficiently to the Azure EventHub.

- Access the [IoT Operations portal](https://iotoperations.azure.com/sites/_/_/_/instances) to view IoT clusters deployed.

  ![Screenshot showing IoT Operations portal](./img/hypermarket-iot-operations-portal.png)

- Select one of the instances to view dataflow endpoints and dataflows that are being used to relay data from edge to cloud.

  ![Screenshot showing IoT Operations dashboard](./img/hypermarket-iot-operations-dashboard.png)

- Click on Dataflow endpoints to view endpoints created for datapipeline.

  ![Screenshot showing IoT Operations dataflow endpoints](./img/hypermarket-iot-operations-dataflow-endpoints.png)

- Click on Dataflows to view dataflows created for datapipeline.

  ![Screenshot showing IoT Operations dataflows](./img/hypermarket-iot-operations-dataflows.png)

- Monitor the data flow and ensure that the commercial data is being transmitted without any issues. Refer Event Hub section below for more details on monitoring messages delivered by dataflows.

- Troubleshoot any connectivity issues and ensure the data pipeline is functioning correctly.

### MQTT Explorer

The MQTT Explorer is a desktop tool included in the Contoso Hypermarket setup. It allows end users to connect to the MQTT listener running in IoT operations at the edge, observe messages generated by the Cerebral simulator, and send test messages to validate the data pipeline during troubleshooting.

- Open the MQTT explorer desktop shortcut, it is already configured to connect to the MQTT listener on the cluster.

  ![Screenshot showing opening MQTT explorer on the desktop](./img/hypermarket-locate-mqtt-explorer.png)

- Notice pre-configured MQTT connections to connect to the MQTT listeners running in IoT operations. Select one of the edge site and click _Connect_

  ![Screenshot showing MQTT explorer with connections](./img/hypermarket-mqtt-explorer-connect.png)

- Once connected, you will start seeing simulated data being transmitted with various metrics from the plant assets.
  1. Topic for the commercial data message publication.
  1. Message received from the Cerebrar similator.
  1. Previous message published in the commercial topic.

  ![Screenshot showing the simulated commercial data](./img/hypermarket-mqtt-explorer-commercial-events.png)

## In the cloud

### Azure EventHub

### Microsoft Fabric

[Microsoft Fabric](https://learn.microsoft.com/fabric/get-started/microsoft-fabric-overview) is a unified platform that integrates various data services to streamline data management and analytics. It includes Event House for event streaming, KQL database for querying large datasets, and PowerBI for creating interactive dashboards. The Realtime dashboard provides up-to-the-minute insights, while Notebook offers a collaborative environment for data exploration and analysis.

### Fabric workspace

The [Fabric workspace](https://learn.microsoft.com/fabric/get-started/workspaces) is a collaborative environment within Microsoft Fabric where data engineers, data scientists, and business analysts can work together on data projects. It provides tools for data ingestion, transformation, and analysis, enabling teams to build and manage data pipelines, create machine learning models, and develop interactive reports. The workspace supports version control, allowing users to track changes and collaborate effectively on data-driven initiatives.

As part of the Contoso Hypermarket deployment Fabric workspace created with all the items required to support data pipeline. Screenshot below shows Contoso Hypermarket Fabric workspace and items to support the scenario.

![Screenshot showing overview of Microsoft Fabric workspace](./img/fabric-workspace.png)

### KQL database

The KQL database in Microsoft Fabric is a powerful tool designed for querying and analyzing large datasets. In the context of Contoso Hypermarket, the KQL database is used to ingest commercial data flowing from edge locations to Azure EventHub. This data includes store orders and inventory information, which is then processed and stored in the KQL database. The database allows for efficient querying and analysis of this data, enabling the generation of real-time insights and reports. By leveraging the KQL database, Contoso Hypermarket can quickly access and analyze critical commercial data to support decision-making and operational efficiency.

Data ingested into KQL database is used by the Power BI reports create for commercial data insights and analysis by the Contoso leadership team.

- Below is the screenshot of KQL database created in the Fabric workspace and it's details.
  1. KQL database name
  1. Database tables used in the Contoso Hypermarket for data ingestion and reports
  1. Datapipeline data ingestion over the time
  1. Database tables ingestion details
  1. KQL database details

  ![Screenshot showing overview of Microsoft Fabric workspace](./img/fabric-kql-database-overview.png)

### PowerBI report

### Sales forecast notebook
